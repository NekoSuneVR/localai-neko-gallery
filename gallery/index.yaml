---
- &llama3
  url: "github:mudler/LocalAI/gallery/llama3-instruct.yaml@master"
  icon: https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/aJJxKus1wP5N-euvHEUq7.png
  name: "llama3-8b-instruct"
  license: llama3
  description: |
    Meta developed and released the Meta Llama 3 family of large language models (LLMs), a collection of pretrained and instruction tuned generative text models in 8 and 70B sizes. The Llama 3 instruction tuned models are optimized for dialogue use cases and outperform many of the available open source chat models on common industry benchmarks. Further, in developing these models, we took great care to optimize helpfulness and safety.

    Model developers Meta

    Variations Llama 3 comes in two sizes — 8B and 70B parameters — in pre-trained and instruction tuned variants.

    Input Models input text only.

    Output Models generate text and code only.

    Model Architecture Llama 3 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.
  urls:
    - https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct
    - https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF
  tags:
    - llm
    - gguf
    - gpu
    - cpu
    - llama3
- !!merge <<: *llama3
  name: "mpt-7b-instruct"
  urls:
    - https://gpt4all.io/
  description: |
        MPT-7B-Instruct is a model for short-form instruction following. It is built by finetuning MPT-7B on a dataset derived from the Databricks Dolly-15k and the Anthropic Helpful and Harmless (HH-RLHF) datasets. 
  overrides:
    parameters:
      model: ggml-mpt-7b-instruct.bin
  files:
    - filename: ggml-mpt-7b-instruct.bin
      uri: https://gpt4all.io/models/ggml-mpt-7b-instruct.bin
      sha256: 3e55408392233201f7b2a2e2822d3292ff1dcc50ff74c101c2e47342664a9b34
- !!merge <<: *llama3
  name: "poppy_porpoise-v0.72-l3-8b-iq-imatrix"
  urls:
    - https://huggingface.co/Lewdiculous/Poppy_Porpoise-0.72-L3-8B-GGUF-IQ-Imatrix
  description: |
    "Poppy Porpoise" is a cutting-edge AI roleplay assistant based on the Llama 3 8B model, specializing in crafting unforgettable narrative experiences. With its advanced language capabilities, Poppy expertly immerses users in an interactive and engaging adventure, tailoring each adventure to their individual preferences.

    Update: Vision/multimodal capabilities again!
  icon: https://cdn-uploads.huggingface.co/production/uploads/642265bc01c62c1e4102dc36/Boje781GkTdYgORTYGI6r.png
  tags:
    - llm
    - multimodal
    - gguf
    - gpu
    - llama3
    - cpu
    - llava-1.5
  overrides:
    mmproj: Llama-3-Update-2.0-mmproj-model-f16.gguf
    parameters:
      model: Poppy_Porpoise-0.72-L3-8B-Q4_K_M-imat.gguf
  files:
    - filename: Poppy_Porpoise-0.72-L3-8B-Q4_K_M-imat.gguf
      sha256: 53743717f929f73aa4355229de114d9b81814cb2e83c6cc1c6517844da20bfd5
      uri: huggingface://Lewdiculous/Poppy_Porpoise-0.72-L3-8B-GGUF-IQ-Imatrix/Poppy_Porpoise-0.72-L3-8B-Q4_K_M-imat.gguf
    - filename: Llama-3-Update-2.0-mmproj-model-f16.gguf
      sha256: 1058494004dfa121439d5a75fb96ea814c7a5937c0529998bf2366f2179bb5ba
      uri: huggingface://Nitral-AI/Llama-3-Update-2.0-mmproj-model-f16/Llama-3-Update-2.0-mmproj-model-f16.gguf
- !!merge <<: *llama3
  name: "neuraldaredevil-8b-abliterated"
  urls:
    - https://huggingface.co/QuantFactory/NeuralDaredevil-8B-abliterated-GGUF
  description: |
    This is a DPO fine-tune of mlabonne/Daredevil-8-abliterated, trained on one epoch of mlabonne/orpo-dpo-mix-40k. The DPO fine-tuning successfully recovers the performance loss due to the abliteration process, making it an excellent uncensored model.
  icon: https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/gFEhcIDSKa3AWpkNfH91q.jpeg
  overrides:
    parameters:
      model: NeuralDaredevil-8B-abliterated.Q4_K_M.gguf
  files:
    - filename: NeuralDaredevil-8B-abliterated.Q4_K_M.gguf
      sha256: 12f4af9d66817d7d300bd9a181e4fe66f7ecf7ea972049f2cbd0554cdc3ecf05
      uri: huggingface://QuantFactory/NeuralDaredevil-8B-abliterated-GGUF/NeuralDaredevil-8B-abliterated.Q4_K_M.gguf
- &whisper
  ## Whisper
  url: "github:mudler/LocalAI/gallery/whisper-base.yaml@master"
  name: "whisper-1"
  license: "MIT"
  urls:
    - https://github.com/ggerganov/whisper.cpp
    - https://huggingface.co/ggerganov/whisper.cpp
  overrides:
    parameters:
      model: ggml-whisper-base.bin
  files:
    - filename: "ggml-whisper-base.bin"
      sha256: "60ed5bc3dd14eea856493d334349b405782ddcaf0028d4b5df4088345fba2efe"
      uri: "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin"
  description: |
    Port of OpenAI's Whisper model in C/C++
- !!merge <<: *whisper
  name: "whisper-large-v2"
  license: "MIT"
  urls:
    - https://github.com/ggerganov/whisper.cpp
    - https://huggingface.co/ggerganov/whisper.cpp
  overrides:
    parameters:
      model: ggml-whisper-large-v2.bin
  files:
    - filename: "ggml-whisper-large-v2.bin"
      sha256: "9a423fe4d40c82774b6af34115b8b935f34152246eb19e80e376071d3f999487"
      uri: "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-large-v2.bin"
  description: |
    Port of OpenAI's Whisper model in C/C++ 
- !!merge <<: *whisper
  name: "whisper-medium"
  license: "MIT"
  urls:
    - https://github.com/ggerganov/whisper.cpp
    - https://huggingface.co/ggerganov/whisper.cpp
  overrides:
    parameters:
      model: ggml-whisper-medium.bin
  files:
    - filename: "ggml-whisper-medium.bin"
      sha256: "6c14d5adee5f86394037b4e4e8b59f1673b6cee10e3cf0b11bbdbee79c156208"
      uri: "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-medium.bin"
  description: |
    Port of OpenAI's Whisper model in C/C++ 
